{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (20, 8)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "plt.style.use('seaborn-darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('../output/train_outputs.csv')\n",
    "data_2 = data_2.drop([data_2.columns[0]], axis='columns')\n",
    "data_2 = data_2.iloc[:, :-3]\n",
    "data_2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# unit='s' to convert it into epoch time\n",
    "data_2['Time'] = pd.to_datetime(data_2['Time'])\n",
    "\n",
    "date_time = data_2['Time'].dt.strftime('%S')\n",
    "\n",
    "\n",
    "# checking our dataframe once again\n",
    "data_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary statistics of the DataFrame\n",
    "print(data_2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = data_2[['Subcar_9', 'Subcar_10', 'Subcar_11', 'Subcar_12' ]]\n",
    "df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.query(\"Subcar_9 > 500\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df_input)\n",
    "data_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features are inputs as well as ta\n",
    "# target value is index 2\n",
    "\n",
    "features = data_scaled\n",
    "target = data_scaled[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeseriesGenerator(features, target, length=6,\n",
    "                    sampling_rate=1, batch_size=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.20, random_state=120, shuffle=False)  # false for timeseries\n",
    "print('X_train.shape: ', x_train.shape)\n",
    "print('X_test.shape: ', x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length = 144  # 1 day = 144 of data, 5 day = 720 of data\n",
    "batch_size = 32\n",
    "num_features = 4\n",
    "train_generator = tf.keras.preprocessing.sequence.TimeseriesGenerator(\n",
    "    x_train, y_train, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator = tf.keras.preprocessing.sequence.TimeseriesGenerator(\n",
    "    x_test, y_test, length=win_length, sampling_rate=1, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128, input_shape=(\n",
    "        win_length, num_features), return_sequences=True),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.5),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.5),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=False),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp1 = ModelCheckpoint('../save/lstm_model_1/', save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "lstm_model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                   metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "val_performance = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm_model.fit(\n",
    "    train_generator, epochs=20,\n",
    "    validation_data=test_generator,\n",
    "    shuffle=False,\n",
    "    callbacks=[early_stopping, cp1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_eval = lstm_model.evaluate(\n",
    "    test_generator, verbose=0\n",
    ")\n",
    "lstm_eval\n",
    "val_performance['LSTM'] = lstm_model.evaluate(train_generator)\n",
    "performance['LSTM'] = lstm_model.evaluate(test_generator, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lstm = lstm_model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "lstm_model = load_model('../save/lstm_model_1/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_lstm = pd.concat([pd.DataFrame(predictions_lstm),\n",
    "                          pd.DataFrame(x_test[:, 1:][win_length:])], axis=1)\n",
    "df_pred_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To the original format\n",
    "rev_trans = scaler.inverse_transform(df_pred_lstm)\n",
    "rev_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_lstm = df_input[predictions_lstm.shape[0]*-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_lstm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_lstm['Subcar_9_pred'] = rev_trans[:, 0]\n",
    "df_final_lstm"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8abc43b3d971bbbfe7bddad7665b0e853331231bc5daa59e6002e2c31ec46845"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('Tensorflow210')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
